{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils.data_loading import BasicDataset, CarvanaDataset\n",
    "\n",
    "dir_img = Path('./data/imgs/')\n",
    "dir_mask = Path('./data/masks/')\n",
    "\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed()\n",
    "\n",
    "\n",
    "try:\n",
    "    dataset = CarvanaDataset(dir_img, dir_mask, 1)\n",
    "except (AssertionError, RuntimeError, IndexError):\n",
    "    dataset = BasicDataset(dir_img, dir_mask, 1)\n",
    "\n",
    "n_val = int(len(dataset) * 0.1)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "loader_args = dict(batch_size=1, num_workers=os.cpu_count(), pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from utils.dice_score import multiclass_dice_coeff, dice_coeff\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(net, dataloader, device, amp):\n",
    "    net.to(device).eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    iou_scores = [0] * net.n_classes\n",
    "    total_true = [0] * net.n_classes\n",
    "    total_pred = [0] * net.n_classes\n",
    "    total_correct = [0] * net.n_classes\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "        for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
    "            image, mask_true = batch['image'], batch['mask']\n",
    "            image = image.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            mask_true = mask_true.to(device=device, dtype=torch.long)\n",
    "            mask_pred = net(image)\n",
    "\n",
    "            if net.n_classes == 1:\n",
    "                mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
    "                mask_true = mask_true.float()\n",
    "            else:\n",
    "                mask_pred = mask_pred.argmax(dim=1)\n",
    "\n",
    "            # Flatten the masks\n",
    "            mask_true = mask_true.view(-1)\n",
    "            mask_pred = mask_pred.view(-1)\n",
    "\n",
    "            # Calculate IoU scores\n",
    "            for i in range(net.n_classes):\n",
    "                true_positives = ((mask_pred == i) & (mask_true == i)).sum().item()\n",
    "                false_positives = ((mask_pred == i) & (mask_true != i)).sum().item()\n",
    "                false_negatives = ((mask_pred != i) & (mask_true == i)).sum().item()\n",
    "                total_true[i] += (mask_true == i).sum().item()\n",
    "                total_pred[i] += (mask_pred == i).sum().item()\n",
    "                total_correct[i] += true_positives\n",
    "\n",
    "                if (true_positives + false_positives + false_negatives) == 0:\n",
    "                    iou_scores[i] = 0  # Avoid division by zero\n",
    "                else:\n",
    "                    iou_scores[i] += true_positives / (true_positives + false_positives + false_negatives)\n",
    "\n",
    "            # Calculate Precision, Recall and F1 for each batch\n",
    "            precision = precision_score(mask_true.cpu().numpy(), mask_pred.cpu().numpy(), average=None)\n",
    "            recall = recall_score(mask_true.cpu().numpy(), mask_pred.cpu().numpy(), average=None)\n",
    "            f1 = f1_score(mask_true.cpu().numpy(), mask_pred.cpu().numpy(), average=None)\n",
    "\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "    # Calculate average IoU, Precision, Recall and F1\n",
    "    iou_scores = [iou_score / num_val_batches for iou_score in iou_scores]\n",
    "    miou = sum(iou_scores[1:]) / (net.n_classes - 1)  # Exclude background class for mIoU\n",
    "    precision_avg = sum([p for sublist in precision_list for p in sublist[1:]]) / (len(precision_list) * (net.n_classes - 1))\n",
    "    recall_avg = sum([r for sublist in recall_list for r in sublist[1:]]) / (len(recall_list) * (net.n_classes - 1))\n",
    "    f1_avg = sum([f for sublist in f1_list for f in sublist[1:]]) / (len(f1_list) * (net.n_classes - 1))\n",
    "    return iou_scores, miou, precision_avg, recall_avg, f1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import UNet\n",
    "from models.railnet import parsingNet\n",
    "from models.unetplusplus import NestedUNet\n",
    "from models.unet3plus import  UNet3Plus\n",
    "from models.unetv2 import UNetV2\n",
    "\n",
    "# 数据路径\n",
    "unet_model_path = 'checkpoints/unet.pth'\n",
    "parsingnet_model_path = 'checkpoints/railnet.pth'\n",
    "unetpp_model_path = 'checkpoints/unetplusplus.pth'\n",
    "unet3plus_model_path = 'checkpoints/unet3plus.pth'\n",
    "unetv2_model_path = 'checkpoints/unetv2.pth'\n",
    "\n",
    "unet = UNet(n_channels=3, n_classes=9, bilinear=False).load_state_dict(torch.load(unet_model_path))\n",
    "parsingnet = parsingNet(n_classes=9).load_state_dict(torch.load(parsingnet_model_path))\n",
    "unetpp = NestedUNet(n_channels=3, n_classes=9).load_state_dict(torch.load(unetpp_model_path))\n",
    "unet3plus = UNet3Plus(n_channels=3, n_classes=9).load_state_dict(torch.load(unet3plus_model_path))\n",
    "unetv2 = UNetV2(n_channels=3, n_classes=9).load_state_dict(torch.load(unetv2_model_path))\n",
    "\n",
    "iou_unet, miou_unet, precision_unet, recall_unet, f1_unet = evaluate(unet, val_loader, device, False)\n",
    "iou_parsingnet, miou_parsingnet, precision_parsingnet, recall_parsingnet, f1_parsingnet = evaluate(parsingnet, val_loader, device, False)\n",
    "iou_unetpp, miou_unetpp, precision_unetpp, recall_unetpp, f1_unetpp = evaluate(unetpp, val_loader, device, False)\n",
    "iou_unet3plus, miou_unet3plus, precision_unet3plus, recall_unet3plus, f1_unet3plus = evaluate(unet3plus, val_loader, device, False)\n",
    "iou_unetv2, miou_unetv2, precision_unetv2, recall_unetv2, f1_unetv2 = evaluate(unetv2, val_loader, device, False)\n",
    "\n",
    "results = {\n",
    "    'UNet': {\n",
    "        'mIoU': miou_unet,\n",
    "        'Precision': precision_unet,\n",
    "        'Recall': recall_unet,\n",
    "        'F1-score': f1_unet\n",
    "    },\n",
    "    'UNet++': {\n",
    "\n",
    "        'mIoU': miou_unetpp,\n",
    "        'Precision': precision_unetpp,\n",
    "        'Recall': recall_unetpp,\n",
    "        'F1-score': f1_unetpp\n",
    "    },\n",
    "    'UNet3Plus': {\n",
    "        \n",
    "        'mIoU': miou_unet3plus,\n",
    "        'Precision': precision_unet3plus,\n",
    "        'Recall': recall_unet3plus,\n",
    "        'F1-score': f1_unet3plus\n",
    "    },\n",
    "    'ParsinNet': {\n",
    "        'mIoU': miou_parsingnet,\n",
    "        'Precision': precision_parsingnet,\n",
    "        'Recall': recall_parsingnet,\n",
    "        'F1-score': f1_parsingnet\n",
    "    },\n",
    "    'UNetv2': {\n",
    "        'mIoU': miou_unetv2,\n",
    "        'Precision': precision_unetv2,\n",
    "        'Recall': recall_unetv2,\n",
    "        'F1-score': f1_unetv2\n",
    "    }\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from models.unet import UNet\n",
    "from models.railnet import parsingNet\n",
    "from models.unetplusplus import NestedUNet\n",
    "\n",
    "# 数据路径\n",
    "imgs_dir = 'data/imgs'\n",
    "masks_dir = 'data/masks'\n",
    "unet_model_path = 'models/unet.pth'\n",
    "parsingnet_model_path = 'models/parsingnet.pth'\n",
    "unetpp_model_path = 'models/unetpp.pth'\n",
    "\n",
    "# 图像预处理\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载UNet模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "unet_model = UNet(n_channels=3, n_classes=9, bilinear=False)\n",
    "unet_model.load_state_dict(torch.load(unet_model_path, map_location=device))\n",
    "unet_model.to(device)\n",
    "unet_model.eval()\n",
    "\n",
    "# 加载ParsingNet模型\n",
    "parsingnet_model = parsingNet(n_channels=3, n_classes=9, bilinear=False)\n",
    "parsingnet_model.load_state_dict(torch.load(parsingnet_model_path, map_location=device))\n",
    "parsingnet_model.to(device)\n",
    "parsingnet_model.eval()\n",
    "\n",
    "# 加载UNet++模型\n",
    "unetpp_model = NestedUNet(n_channels=3, n_classes=9)\n",
    "unetpp_model.load_state_dict(torch.load(unetpp_model_path, map_location=device))\n",
    "unetpp_model.to(device)\n",
    "unetpp_model.eval()\n",
    "\n",
    "# 获取图像和掩码的文件名列表\n",
    "imgs_list = [os.path.join(imgs_dir, file) for file in os.listdir(imgs_dir)]\n",
    "masks_list = [os.path.join(masks_dir, file) for file in os.listdir(masks_dir)]\n",
    "\n",
    "# 确保图像和掩码文件名匹配\n",
    "selected_indices = random.sample(range(len(imgs_list)), 9)\n",
    "selected_imgs = [imgs_list[i] for i in selected_indices]\n",
    "selected_masks = [masks_list[i] for i in selected_indices]\n",
    "\n",
    "# 创建子图网格\n",
    "fig, axs = plt.subplots(9, 4, figsize=(20, 30))  # 9行4列的子图网格\n",
    "plt.rcParams['font.sans-serif'] = ['times new roman']  # 设置字体为Times New Roman\n",
    "\n",
    "# 设置列标题\n",
    "axs[0, 0].set_title('Ground Truth', fontsize=12)\n",
    "axs[0, 1].set_title('UNet', fontsize=12)\n",
    "axs[0, 2].set_title('UNet++', fontsize=12)\n",
    "axs[0, 3].set_title('Rail-Net', fontsize=12)\n",
    "\n",
    "for i, (img_path, mask_path) in enumerate(zip(selected_imgs, selected_masks)):\n",
    "    # 加载图像和掩码\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    \n",
    "    # 预处理图像\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # UNet模型预测\n",
    "    with torch.no_grad():\n",
    "        unet_pred_mask = unet_model(img_tensor)\n",
    "        unet_pred_mask = torch.argmax(unet_pred_mask, dim=1).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # UNet++模型预测\n",
    "    with torch.no_grad():\n",
    "        unetpp_pred_mask = unetpp_model(img_tensor)\n",
    "        unetpp_pred_mask = torch.argmax(unetpp_pred_mask, dim=1).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # ParsingNet模型预测\n",
    "    with torch.no_grad():\n",
    "        parsingnet_pred_mask = parsingnet_model(img_tensor)\n",
    "        parsingnet_pred_mask = torch.argmax(parsingnet_pred_mask, dim=1).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # 将预测掩码转换为灰度图像\n",
    "    unet_pred_mask = np.vectorize(lambda x: 1 if x > 0 else 0)(unet_pred_mask)\n",
    "    unetpp_pred_mask = np.vectorize(lambda x: 1 if x > 0 else 0)(unetpp_pred_mask)\n",
    "    parsingnet_pred_mask = np.vectorize(lambda x: 1 if x > 0 else 0)(parsingnet_pred_mask)\n",
    "    \n",
    "    # 可视化掩码和预测结果\n",
    "    axs[i, 0].imshow(mask, cmap='gray')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(unet_pred_mask, cmap='gray')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    axs[i, 2].imshow(unetpp_pred_mask, cmap='gray')\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "    axs[i, 3].imshow(parsingnet_pred_mask, cmap='gray')\n",
    "    axs[i, 3].axis('off')\n",
    "\n",
    "# 调整子图间距\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
